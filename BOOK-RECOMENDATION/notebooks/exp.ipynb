{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ebaa62",
   "metadata": {},
   "source": [
    "# 📚 AI & ML Research Paper and Book Recommender Dataset Project\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Project Overview\n",
    "The purpose of this project is to **create a comprehensive dataset of research papers and books** in the fields of **Machine Learning (ML), Deep Learning (DL), Artificial Intelligence (AI), Natural Language Processing (NLP), Data Science, and related areas**.  \n",
    "This dataset will later serve as the foundation for building a **recommendation system** that can suggest highly relevant and impactful resources to learners, researchers, and professionals.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Motivation\n",
    "With the rapid growth of AI/ML research and publications, it is increasingly difficult for students, researchers, and practitioners to **identify high-quality and relevant resources** efficiently.  \n",
    "A curated dataset of books and research papers enables:  \n",
    "- Quick discovery of important research papers and books  \n",
    "- Recommendations based on relevance, citations, recency, and topic  \n",
    "- Support for personalized learning and knowledge expansion  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Project Goals\n",
    "1. **Fetch books** related to ML, DL, AI, NLP, and Data Science from the **Google Books API**.  \n",
    "2. **Fetch research papers** in the same domains from the **Semantic Scholar API**.  \n",
    "3. **Store data** in both **raw JSON** and **refined CSV** formats for easy analysis and use.  \n",
    "4. **Include key information**:  \n",
    "   - Title, Abstract, Authors, Publication Year, Citations, Venue/Publisher, URL  \n",
    "5. **Prepare the dataset** for future use in building a **recommendation system** combining books and research papers.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Key Features of the Dataset\n",
    "- Covers multiple **ML/AI/NLP categories** with a wide range of resources  \n",
    "- Includes **academic impact signals** (citation counts for papers, ratings for books)  \n",
    "- Handles **duplicates and filtering** to ensure quality  \n",
    "- Easy to use for **data analysis, visualization, and recommender systems**  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Tools & APIs Used\n",
    "- **Python** for data fetching, processing, and storage  \n",
    "- **Google Books API** to fetch books data  \n",
    "- **Semantic Scholar API** to fetch research papers data  \n",
    "- **Pandas** for refining and saving datasets  \n",
    "- **JSON & CSV** for storing data in structured and human-readable formats  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Future Scope\n",
    "- Merge book and paper datasets for a **unified recommendation engine**  \n",
    "- Rank resources by **relevance, citations, recency, and ratings**  \n",
    "- Build **personalized ML/NLP learning recommendations**  \n",
    "- Expand dataset with **more topics and research domains**  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Notebook Structure\n",
    "1. **Introduction & Motivation**  \n",
    "2. **Setup & Library Imports**  \n",
    "3. **Define Functions to Fetch & Save Data**  \n",
    "4. **Define Queries for Books & Papers**  \n",
    "5. **Fetch Data from APIs**  \n",
    "6. **Save Raw JSON & Refined CSV**  \n",
    "7. **Preview & Analyze Dataset**  \n",
    "8. **Next Steps for Recommender System**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c168ed",
   "metadata": {},
   "source": [
    "# Importing the Required Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching data from api\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "# Data Exploration \n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b0dea",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1ffef",
   "metadata": {},
   "source": [
    "## Loading the books info from Google Books Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1335 books and saved to data/Ml_books.json\n"
     ]
    }
   ],
   "source": [
    "# API_KEY=\"My_API_KEY\"\n",
    "# queries = [\n",
    "#     'intitle:\"machine learning\"',\n",
    "#     'intitle:\"deep learning\"',\n",
    "#     'intitle:\"artificial intelligence\"',\n",
    "#     'intitle:\"natural language processing\"',\n",
    "#     'intitle:\"data science\"',\n",
    "#     'intitle:\"computer vision\"',\n",
    "#     'intitle:\"reinforcement learning\"',\n",
    "#     'intitle:\"ML algorithms\"',\n",
    "#     'intitle:\"AI research\"',\n",
    "#     'intitle:\"neural networks\"'\n",
    "# ]\n",
    "\n",
    "# all_books = []\n",
    "\n",
    "# for q in queries:\n",
    "#     for start in range(0,400,40):\n",
    "#         url= url = f\"https://www.googleapis.com/books/v1/volumes?q={q}&maxResults=40&startIndex={start}&key={API_KEY}\"\n",
    "#         response=requests.get(url)\n",
    "#         data=response.json()\n",
    "#         items=data.get(\"items\",[])\n",
    "#         all_books.extend(items)\n",
    "#         time.sleep(0.8)\n",
    "        \n",
    "\n",
    "# with open(\"data/Ml_books.json\",\"w\",encoding=\"utf=8\") as f:\n",
    "#     json.dump(all_books,f,ensure_ascii=False,indent=4)\n",
    "    \n",
    "# print(f\"Fetched {len(all_books)} books and saved to data/Ml_books.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the saved Json file\n",
    "# with open(\"data/Ml_books.json\",\"r\") as f:\n",
    "#     all_books=json.load(f)\n",
    "\n",
    "# # Relevant key words\n",
    "# ml_keywords = [\n",
    "#     \"machine learning\",\n",
    "#     \"deep learning\",\n",
    "#     \"artificial intelligence\",\n",
    "#     \"natural language processing\",\n",
    "#     \"nlp\",\n",
    "#     \"data science\",\n",
    "#     \"computer vision\",\n",
    "#     \"reinforcement learning\",\n",
    "#     \"ml algorithms\",\n",
    "#     \"ai research\",\n",
    "#     \"neural networks\"\n",
    "# ]\n",
    "\n",
    "# # Refining the data with relevent key words\n",
    "# filtered_books = []\n",
    "# for item in all_books:\n",
    "#     title = item[\"volumeInfo\"].get(\"title\", \"\").lower()\n",
    "#     desc = item[\"volumeInfo\"].get(\"description\", \"\").lower()\n",
    "#     if any(k in title or k in desc for k in ml_keywords):\n",
    "#         filtered_books.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32747a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered books to data/ml_books.csv\n"
     ]
    }
   ],
   "source": [
    "# # Saving the CSV Dataset with relevent features\n",
    "# books_list = []\n",
    "# for item in filtered_books:\n",
    "#     info = item[\"volumeInfo\"]\n",
    "#     books_list.append({\n",
    "#         \"title\": info.get(\"title\"),\n",
    "      \n",
    "#         \"authors\": \", \".join(info.get(\"authors\", [])),\n",
    "#         \"description\": info.get(\"description\", \"\"),\n",
    "#         \"categories\": \", \".join(info.get(\"categories\", [])),\n",
    "#         \"publisher\":info.get('publisher',[]),\n",
    "#         \"publishedDate\": info.get(\"publishedDate\", \"\"),\n",
    "#         \"avgrating\":info.get(\"averageRating\", 0),\n",
    "#         \"pagecount\":info.get(\"pageCount\",0),\n",
    " \n",
    "#     })\n",
    "\n",
    "# df = pd.DataFrame(books_list)\n",
    "# df.to_csv(\"data/ml_books.csv\", index=False)\n",
    "# print(\"Saved filtered books to data/ml_books.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89030132",
   "metadata": {},
   "source": [
    "## Loading the Research papers from Semanticscholar.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to fetch the papers\n",
    "# def fetch_papers(query, limit=100, max_results=300):\n",
    "#     \"\"\"\n",
    "#     Fetch research papers from Semantic Scholar API.\n",
    "#     query: search keyword (e.g., \"machine learning\")\n",
    "#     limit: results per API call (max 100)\n",
    "#     max_results: total number of results to fetch\n",
    "#     \"\"\"\n",
    "#     papers = []\n",
    "#     base_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "#     fields = \"title,abstract,authors,url,year,citationCount,venue\"\n",
    "\n",
    "#     for offset in range(0, max_results, limit):\n",
    "#         url = f\"{base_url}?query={query}&limit={limit}&offset={offset}&fields={fields}\"\n",
    "#         response = requests.get(url)\n",
    "\n",
    "#         if response.status_code != 200:\n",
    "#             print(\"Error fetching\", query, \":\", response.status_code)\n",
    "#             break\n",
    "\n",
    "#         data = response.json()\n",
    "#         items = data.get(\"data\", [])\n",
    "#         if not items:\n",
    "#             break\n",
    "\n",
    "#         # Attach query label for reference\n",
    "#         for item in items:\n",
    "#             item[\"searchQuery\"] = query\n",
    "#         papers.extend(items)\n",
    "\n",
    "#         time.sleep(1)  # avoid hitting API too fast\n",
    "\n",
    "#     return papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Function to save results\n",
    "# def save_papers(papers, json_file=\"papers.json\", csv_file=\"papers.csv\"):\n",
    "#     \"\"\"\n",
    "#     Save papers to JSON (raw) and CSV (refined).\n",
    "#     \"\"\"\n",
    "#     # Save raw JSON\n",
    "#     with open(json_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(papers, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "#     # Refine for CSV\n",
    "#     refined = []\n",
    "#     for p in papers:\n",
    "#         refined.append({\n",
    "#             \"SearchQuery\": p.get(\"searchQuery\", \"\"),\n",
    "#             \"Title\": p.get(\"title\", \"\"),\n",
    "#             \"Abstract\": p.get(\"abstract\", \"\"),\n",
    "#             \"Authors\": \", \".join([a.get(\"name\", \"\") for a in p.get(\"authors\", [])]),\n",
    "#             \"Year\": p.get(\"year\", \"\"),\n",
    "#             \"Citations\": p.get(\"citationCount\", 0),\n",
    "#             \"Venue\": p.get(\"venue\", \"\"),\n",
    "#             \"URL\": p.get(\"url\", \"\")\n",
    "#         })\n",
    "\n",
    "#     df = pd.DataFrame(refined)\n",
    "#     df.to_csv(csv_file, index=False, encoding=\"utf-8\")\n",
    "#     print(f\"Saved {len(refined)} papers → {json_file}, {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for: machine learning\n",
      "Error fetching machine learning : 429\n",
      "Fetching papers for: deep learning\n",
      "Error fetching deep learning : 429\n",
      "Fetching papers for: artificial intelligence\n",
      "Error fetching artificial intelligence : 429\n",
      "Fetching papers for: natural language processing\n",
      "Fetching papers for: nlp\n",
      "Error fetching nlp : 429\n",
      "Fetching papers for: computer vision\n",
      "Error fetching computer vision : 429\n",
      "Fetching papers for: reinforcement learning\n",
      "Error fetching reinforcement learning : 429\n",
      "Fetching papers for: data science\n",
      "Error fetching data science : 429\n",
      "Saved 600 papers → data/all_papers.json, data/all_papers.csv\n"
     ]
    }
   ],
   "source": [
    "# # Loading the papers with Relevant key words\n",
    "# queries = [\n",
    "#     \"machine learning\",\n",
    "#     \"deep learning\",\n",
    "#     \"artificial intelligence\",\n",
    "#     \"natural language processing\",\n",
    "#     \"nlp\",\n",
    "#     \"computer vision\",\n",
    "#     \"reinforcement learning\",\n",
    "#     \"data science\"\n",
    "# ]\n",
    "\n",
    "# all_papers = []\n",
    "# for q in queries:\n",
    "#     print(f\"Fetching papers for: {q}\")\n",
    "#     papers = fetch_papers(q, limit=100, max_results=300) \n",
    "#     all_papers.extend(papers)\n",
    "\n",
    "# save_papers(all_papers, json_file=\"data/all_papers.json\", csv_file=\"data/all_papers.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824376e",
   "metadata": {},
   "source": [
    "# 🔍 Data Inspection & Preview\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "Before using the dataset for analysis or building a recommendation system, it is important to **explore and inspect the data** to ensure:  \n",
    "- Data was fetched correctly from the APIs  \n",
    "- All key fields (Title, Abstract, Authors, Year, Citations, URL) are present  \n",
    "- There are no duplicates or missing values  \n",
    "- The dataset covers all intended categories  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93d41fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>avgrating</th>\n",
       "      <th>pagecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Machine Learning</td>\n",
       "      <td>Sebastian Raschka, Vahid Mirjalili</td>\n",
       "      <td>Applied machine learning with a solid foundati...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>Packt Publishing Ltd</td>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Introduction to Machine Learning</td>\n",
       "      <td>Ethem Alpaydin</td>\n",
       "      <td>An introductory text in machine learning that ...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>MIT Press</td>\n",
       "      <td>2004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Understanding Machine Learning</td>\n",
       "      <td>Shai Shalev-Shwartz, Shai Ben-David</td>\n",
       "      <td>Introduces machine learning and its algorithmi...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "      <td>2014-05-19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Introduction to Machine Learning, fourth edition</td>\n",
       "      <td>Ethem Alpaydin</td>\n",
       "      <td>A substantially revised fourth edition of a co...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>MIT Press</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hands-On Machine Learning with Scikit-Learn, K...</td>\n",
       "      <td>Aurélien Géron</td>\n",
       "      <td>Through a series of recent breakthroughs, deep...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>O'Reilly Media</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                            Python Machine Learning   \n",
       "1                   Introduction to Machine Learning   \n",
       "2                     Understanding Machine Learning   \n",
       "3   Introduction to Machine Learning, fourth edition   \n",
       "4  Hands-On Machine Learning with Scikit-Learn, K...   \n",
       "\n",
       "                               authors  \\\n",
       "0   Sebastian Raschka, Vahid Mirjalili   \n",
       "1                       Ethem Alpaydin   \n",
       "2  Shai Shalev-Shwartz, Shai Ben-David   \n",
       "3                       Ethem Alpaydin   \n",
       "4                       Aurélien Géron   \n",
       "\n",
       "                                         description categories  \\\n",
       "0  Applied machine learning with a solid foundati...  Computers   \n",
       "1  An introductory text in machine learning that ...  Computers   \n",
       "2  Introduces machine learning and its algorithmi...  Computers   \n",
       "3  A substantially revised fourth edition of a co...  Computers   \n",
       "4  Through a series of recent breakthroughs, deep...  Computers   \n",
       "\n",
       "                    publisher publishedDate  avgrating  pagecount  \n",
       "0        Packt Publishing Ltd    2019-12-12        0.0        771  \n",
       "1                   MIT Press          2004        4.0        468  \n",
       "2  Cambridge University Press    2014-05-19        5.0        415  \n",
       "3                   MIT Press    2020-03-24        0.0        709  \n",
       "4              O'Reilly Media    2019-09-05        0.0        851  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOOKS DataFrame\n",
    "df_books=pd.read_csv(\"data/ml_books.csv\")\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f00bf5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SearchQuery</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Venue</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>Peeking Inside the Black-Box: A Survey on Expl...</td>\n",
       "      <td>At the dawn of the fourth industrial revolutio...</td>\n",
       "      <td>Amina Adadi, M. Berrada</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>4078</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>https://www.semanticscholar.org/paper/21dff47a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>High-performance medicine: the convergence of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E. Topol</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4910</td>\n",
       "      <td>Nature Network Boston</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f134abea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>Sparks of Artificial General Intelligence: Ear...</td>\n",
       "      <td>Artificial intelligence (AI) researchers have ...</td>\n",
       "      <td>Sébastien Bubeck, Varun Chandrasekaran, Ronen ...</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>3388</td>\n",
       "      <td>arXiv.org</td>\n",
       "      <td>https://www.semanticscholar.org/paper/8dbd5746...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>Explainable Artificial Intelligence (XAI): Con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alejandro Barredo Arrieta, Natalia Díaz Rodríg...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>6788</td>\n",
       "      <td>Information Fusion</td>\n",
       "      <td>https://www.semanticscholar.org/paper/530a059c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>Explanation in Artificial Intelligence: Insigh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4511</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>https://www.semanticscholar.org/paper/e89dfa30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SearchQuery                                              Title  \\\n",
       "0  artificial intelligence  Peeking Inside the Black-Box: A Survey on Expl...   \n",
       "1  artificial intelligence  High-performance medicine: the convergence of ...   \n",
       "2  artificial intelligence  Sparks of Artificial General Intelligence: Ear...   \n",
       "3  artificial intelligence  Explainable Artificial Intelligence (XAI): Con...   \n",
       "4  artificial intelligence  Explanation in Artificial Intelligence: Insigh...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  At the dawn of the fourth industrial revolutio...   \n",
       "1                                                NaN   \n",
       "2  Artificial intelligence (AI) researchers have ...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             Authors    Year  Citations  \\\n",
       "0                            Amina Adadi, M. Berrada  2018.0       4078   \n",
       "1                                           E. Topol  2019.0       4910   \n",
       "2  Sébastien Bubeck, Varun Chandrasekaran, Ronen ...  2023.0       3388   \n",
       "3  Alejandro Barredo Arrieta, Natalia Díaz Rodríg...  2019.0       6788   \n",
       "4                                         Tim Miller  2017.0       4511   \n",
       "\n",
       "                     Venue                                                URL  \n",
       "0              IEEE Access  https://www.semanticscholar.org/paper/21dff47a...  \n",
       "1    Nature Network Boston  https://www.semanticscholar.org/paper/f134abea...  \n",
       "2                arXiv.org  https://www.semanticscholar.org/paper/8dbd5746...  \n",
       "3       Information Fusion  https://www.semanticscholar.org/paper/530a059c...  \n",
       "4  Artificial Intelligence  https://www.semanticscholar.org/paper/e89dfa30...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PAPER DataFrame\n",
    "df_paper=pd.read_csv(\"data/all_papers.csv\")\n",
    "df_paper.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4b0e0",
   "metadata": {},
   "source": [
    "### DataFrame Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dd9c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296 entries, 0 to 1295\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   title          1296 non-null   object \n",
      " 1   authors        1273 non-null   object \n",
      " 2   description    1180 non-null   object \n",
      " 3   categories     1187 non-null   object \n",
      " 4   publisher      1296 non-null   object \n",
      " 5   publishedDate  1283 non-null   object \n",
      " 6   avgrating      1296 non-null   float64\n",
      " 7   pagecount      1296 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 81.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7232bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SearchQuery  600 non-null    object \n",
      " 1   Title        600 non-null    object \n",
      " 2   Abstract     381 non-null    object \n",
      " 3   Authors      595 non-null    object \n",
      " 4   Year         596 non-null    float64\n",
      " 5   Citations    600 non-null    int64  \n",
      " 6   Venue        549 non-null    object \n",
      " 7   URL          600 non-null    object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_paper.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93554911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Books</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Papers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>avgrating</th>\n",
       "      <th>pagecount</th>\n",
       "      <th>Year</th>\n",
       "      <th>Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1296.000000</td>\n",
       "      <td>1296.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>366.627315</td>\n",
       "      <td>2018.906040</td>\n",
       "      <td>1052.273333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.209872</td>\n",
       "      <td>288.636565</td>\n",
       "      <td>5.232211</td>\n",
       "      <td>4890.785858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>116.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>267.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>479.250000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>590.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3296.000000</td>\n",
       "      <td>2025.000000</td>\n",
       "      <td>99369.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Books                    Papers              \n",
       "         avgrating    pagecount         Year     Citations\n",
       "count  1296.000000  1296.000000   596.000000    600.000000\n",
       "mean      0.343750   366.627315  2018.906040   1052.273333\n",
       "std       1.209872   288.636565     5.232211   4890.785858\n",
       "min       0.000000     0.000000  1980.000000      0.000000\n",
       "25%       0.000000   203.000000  2018.000000    116.750000\n",
       "50%       0.000000   318.000000  2020.000000    267.500000\n",
       "75%       0.000000   479.250000  2022.000000    590.500000\n",
       "max       5.000000  3296.000000  2025.000000  99369.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Combine numeric descriptions side by side\n",
    "desc_books = df_books.describe()\n",
    "desc_papers = df_paper.describe()\n",
    "\n",
    "combined_desc = pd.concat([desc_books, desc_papers], axis=1, keys=[\"Books\", \"Papers\"])\n",
    "display(combined_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b44ac",
   "metadata": {},
   "source": [
    "### Checking the Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8ac8ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title              0\n",
       "authors           23\n",
       "description      116\n",
       "categories       109\n",
       "publisher          0\n",
       "publishedDate     13\n",
       "avgrating          0\n",
       "pagecount          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf9fb0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchQuery      0\n",
       "Title            0\n",
       "Abstract       219\n",
       "Authors          5\n",
       "Year             4\n",
       "Citations        0\n",
       "Venue           51\n",
       "URL              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a01dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
