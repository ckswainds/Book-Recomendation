

# ğŸ“š AI Book & Research Paper Recommender

![Project Banner](https://img.shields.io/badge/ML-Content--Based-blue) ![Python](https://img.shields.io/badge/Python-3.11-green) ![FastAPI](https://img.shields.io/badge/FastAPI-API-red) ![DVC](https://img.shields.io/badge/DVC-Versioning-orange)

A **content-based recommendation system** that suggests top **books and research papers** based on user queries.
The project integrates multiple components â€” **data ingestion, preprocessing, feature extraction, and recommendation** â€” into a reproducible pipeline.

---

## ğŸš€ Overview

This project helps users discover relevant academic and technical resources by leveraging **semantic similarity** between user queries and textual data from books and papers.

* ğŸ“˜ **Book data** fetched from **Google Books API**
* ğŸ“„ **Research paper data** fetched from **Semantic Scholar API**
* ğŸ§  Uses **Sentence Transformers** to compute semantic embeddings
* âš™ï¸ Implements **data version control (DVC)** for reproducibility
* ğŸ³ Deployable using **Docker**, compatible with **Vercel / Render**
* ğŸ’¾ Pipelines for ingestion, cleaning, feature building, and model inference

---

## ğŸ§© Features

* ğŸ” Recommend **top N books and papers** for any query (AI, ML, NLP, or Electronics-related).
* ğŸ§  **Sentence Transformer embeddings** for deep semantic understanding.
* ğŸ§¾ Metadata-aware ranking using title, authors, publisher, year, and citations.
* âš¡ **FastAPI-based backend** and **responsive web frontend** (HTML + TailwindCSS).
* ğŸ”„ **DVC-tracked pipelines** ensure reproducibility of every experiment stage.
* ğŸ§± **Modular architecture** for extending recommendation logic or adding new models easily.
* ğŸ“¦ **Config-driven pipeline** (YAML-based) for flexible experimentation.

---

## ğŸ§  Approach to Solution

1. **Data Ingestion** â€“ Collected raw data from **Google Books API** and **Semantic Scholar API** for AI, ML, NLP, and Electronics-related topics.
2. **Preprocessing** â€“ Cleaned and standardized metadata (author, publisher, descriptions). Unknown fields were labeled as `"Unknown"`.
3. **Feature Engineering** â€“ Combined textual data (title, author, abstract, description) into a single representation.
4. **Embeddings** â€“ Generated high-dimensional embeddings using **Sentence Transformers** to capture semantic meaning.
5. **Similarity Computation** â€“ Calculated **cosine similarity** between user query embeddings and resource embeddings.
6. **Ranking & Recommendation** â€“ Returned top N matches sorted by similarity scores.
7. **Versioning & Reproducibility** â€“ Managed datasets, intermediate files, and trained models using **DVC**.
8. **Deployment** â€“ Containerized the FastAPI app with **Docker**, ready for deployment on **Streamlit/HuggingFace**.

---

## ğŸ§© MLOps & Pipeline Design

| Component                    | Description                                                                           |
| ---------------------------- | ------------------------------------------------------------------------------------- |
| **DVC**                      | Used for data and model versioning, ensuring reproducibility and experiment tracking. |
| **Modular Pipeline**         | Separate stages for ingestion, cleaning, feature building, training, and evaluation.  |
| **YAML Configuration**       | Dynamic config-driven system for changing topics, paths, and model parameters.        |
| **Logging & Error Handling** | Custom logger for tracing pipeline execution and runtime issues.                      |
| **CI/CD Ready**              | Compatible with GitHub Actions for automated data validation and deployment.          |

---

## ğŸ§± Project Structure

```
BOOK-RECOMMENDATION/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile                     # Useful commands: make data / make train
â”œâ”€â”€ configs                      # Config files (YAML for models and ingestion)
â”‚   â”œâ”€â”€ books_topics.yaml
â”‚   â””â”€â”€ papers_topics.yaml
â”‚
â”œâ”€â”€ data                         # Data versioned by DVC
â”‚   â”œâ”€â”€ raw                      # Raw data from APIs
â”‚   â”œâ”€â”€ interim                  # Cleaned/merged data
â”‚   â”œâ”€â”€ processed                # Final datasets ready for modeling
â”‚   â””â”€â”€ external                 # Third-party or sample data
â”‚
â”œâ”€â”€ models                       # Stored model embeddings or trained models
â”‚
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data                     # Data engineering scripts
â”‚   â”‚   â”œâ”€â”€ ingestion.py         # Fetches data from APIs
â”‚   â”‚   â”œâ”€â”€ cleaning.py          # Handles missing values, standardizes fields
â”‚   â”‚   â”œâ”€â”€ build_features.py    # Creates embeddings and features
â”‚   â”‚   â”œâ”€â”€ splitting.py         # Handles dataset splitting
â”‚   â”‚   â””â”€â”€ validation.py        # Validates pipeline data integrity
â”‚   â”‚
â”‚   â”œâ”€â”€ models                   # ML logic for recommendation
â”‚   â”‚   â”œâ”€â”€ model.py             # Embedding + Similarity logic
â”‚   â”‚   â”œâ”€â”€ train.py             # Embedding generation
â”‚   â”‚   â”œâ”€â”€ predict.py           # Top N recommendation
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # Text preprocessing utilities
â”‚   â”‚   â””â”€â”€ hyperparameter_tuning.py
â”‚   â”‚
â”‚   â””â”€â”€ visualization
â”‚       â”œâ”€â”€ evaluation.py        # Evaluate ranking performance
â”‚       â””â”€â”€ exploration.py       # Exploratory plots for data analysis
â”‚
â”œâ”€â”€ app.py                       # FastAPI entry point
â”œâ”€â”€ Dockerfile                   # For containerized deployment
â”œâ”€â”€ dvc.yaml                     # Defines the pipeline stages
â”œâ”€â”€ dvc.lock                     # Tracks file versions
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.py
```

---

## âš™ï¸ Tech Stack

* **Backend:** FastAPI
* **Model:** Sentence Transformers (`all-MiniLM-L6-v2`)
* **Data Management:** DVC
* **Frontend:** TailwindCSS + HTML Templates
* **Deployment:** Docker + Render/Vercel
* **APIs Used:** Google Books API, Semantic Scholar API

---

## ğŸ§° Installation

```bash
git clone https://github.com/yourusername/Book-Recommendation.git
cd Book-Recommendation
pip install -r requirements.txt
```

### Run locally

```bash
uvicorn app:app --host 0.0.0.0 --port 7860
```

---

## ğŸª£ Using Google Drive as DVC Remote

Add remote:

```bash
dvc remote add -d gdrive gdrive://<folder-id>
dvc push
```

---

## ğŸ³ Docker Setup

```bash
docker build -t book_recommendation .
docker run -p 7860:7860 book_recommendation
```

---

## ğŸ“ˆ Future Enhancements

* ğŸ§© Integrate **hybrid filtering** (content + collaborative).
* ğŸ“š Add **dynamic topic expansion** using LLMs.
* ğŸ”„ Auto-update new papers/books from APIs.
* â˜ï¸ Deploy with **CI/CD** using GitHub Actions + DVC Remote.
* ğŸ§® Store embeddings in **vector database** (FAISS / Pinecone).

---